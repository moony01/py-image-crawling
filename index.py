"""
ìƒê²¬ë¡€ ì–¼êµ´ìƒ í…ŒìŠ¤íŠ¸ - ì´ë¯¸ì§€ í¬ë¡¤ëŸ¬
Teachable Machine í•™ìŠµìš© ì´ë¯¸ì§€ ìˆ˜ì§‘

ì‚¬ìš©ë²•: python index.py
"""

from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
import time
import urllib.request
import os
import ssl

# SSL ì¸ì¦ì„œ ê²€ì¦ ë¹„í™œì„±í™” (ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì—ëŸ¬ ë°©ì§€)
ssl._create_default_https_context = ssl._create_unverified_context


def create_directory(directory):
    """ë””ë ‰í† ë¦¬ ìƒì„±"""
    try:
        if not os.path.exists(directory):
            os.makedirs(directory)
            print(f"ğŸ“ í´ë” ìƒì„±: {directory}")
    except OSError as e:
        print(f"âŒ í´ë” ìƒì„± ì‹¤íŒ¨: {e}")


def crawling_img(name, category, max_count=100):
    """
    Google ì´ë¯¸ì§€ í¬ë¡¤ë§
    
    Args:
        name: ê²€ìƒ‰ì–´ (ì˜ˆ: "ì°¨ì€ìš° ì–¼êµ´")
        category: ì €ì¥ í´ë”ëª… (ì˜ˆ: "í”„ë¦¬íŒ¨ìŠ¤ìƒ", "ë¬¸ì „ë°•ëŒ€ìƒ")
        max_count: ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜ (ê¸°ë³¸ 100ì¥)
    """
    print(f"\nğŸ” í¬ë¡¤ë§ ì‹œì‘: {name} â†’ {category}")
    
    # Chrome ì˜µì…˜ ì„¤ì •
    options = webdriver.ChromeOptions()
    options.add_experimental_option("excludeSwitches", ["enable-logging"])
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("--lang=ko_KR")
    # options.add_argument("--headless")  # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ì›í•˜ë©´ ì£¼ì„ í•´ì œ
    
    # WebDriver ìë™ ê´€ë¦¬ (Chrome ë²„ì „ ìë™ ë§¤ì¹­)
    driver = webdriver.Chrome(
        service=Service(ChromeDriverManager().install()),
        options=options
    )
    
    try:
        # Google ì´ë¯¸ì§€ ê²€ìƒ‰
        driver.get("https://www.google.co.kr/imghp?hl=ko")
        time.sleep(1)
        
        # ê²€ìƒ‰ì–´ ì…ë ¥
        search_box = driver.find_element(By.NAME, "q")
        search_box.send_keys(name)
        search_box.send_keys(Keys.RETURN)
        time.sleep(2)
        
        # ìŠ¤í¬ë¡¤í•˜ì—¬ ì´ë¯¸ì§€ ë” ë¡œë“œ
        SCROLL_PAUSE_TIME = 1.5
        last_height = driver.execute_script("return document.body.scrollHeight")
        
        scroll_count = 0
        max_scrolls = 10  # ìµœëŒ€ ìŠ¤í¬ë¡¤ íšŸìˆ˜
        
        while scroll_count < max_scrolls:
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(SCROLL_PAUSE_TIME)
            
            new_height = driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                # "ê²°ê³¼ ë”ë³´ê¸°" ë²„íŠ¼ í´ë¦­ ì‹œë„
                try:
                    more_btn = driver.find_element(By.CSS_SELECTOR, ".mye4qd")
                    if more_btn.is_displayed():
                        more_btn.click()
                        time.sleep(1)
                except:
                    break
            
            last_height = new_height
            scroll_count += 1
        
        # ì´ë¯¸ì§€ ìš”ì†Œ ì°¾ê¸° (ì—¬ëŸ¬ ì…€ë ‰í„° ì‹œë„)
        selectors = [".rg_i.Q4LuWd", "img.rg_i", "[data-src]"]
        imgs = []
        
        for selector in selectors:
            imgs = driver.find_elements(By.CSS_SELECTOR, selector)
            if len(imgs) > 0:
                print(f"âœ… ì…€ë ‰í„° '{selector}'ë¡œ {len(imgs)}ê°œ ì´ë¯¸ì§€ ë°œê²¬")
                break
        
        if not imgs:
            print("âŒ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Google í˜ì´ì§€ êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return
        
        # ì €ì¥ í´ë” ìƒì„± (ìƒëŒ€ ê²½ë¡œ)
        base_dir = os.path.dirname(os.path.abspath(__file__))
        save_dir = os.path.join(base_dir, "dataset", category)
        create_directory(save_dir)
        
        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        count = 0
        for i, img in enumerate(imgs):
            if count >= max_count:
                break
                
            try:
                # ì´ë¯¸ì§€ í´ë¦­í•˜ì—¬ ê³ í™”ì§ˆ ë²„ì „ ì—´ê¸°
                img.click()
                time.sleep(1.5)
                
                # ê³ í™”ì§ˆ ì´ë¯¸ì§€ URL ì¶”ì¶œ (ì—¬ëŸ¬ XPath ì‹œë„)
                xpaths = [
                    '//img[contains(@class, "sFlh5c")]',
                    '//img[contains(@class, "n3VNCb")]',
                    '//img[contains(@class, "iPVvYb")]',
                    '//*[@id="Sva75c"]//img[@src and @alt]'
                ]
                
                img_url = None
                for xpath in xpaths:
                    try:
                        large_img = driver.find_element(By.XPATH, xpath)
                        img_url = large_img.get_attribute("src")
                        if img_url and img_url.startswith("http") and "google" not in img_url:
                            break
                    except:
                        continue
                
                if not img_url or not img_url.startswith("http"):
                    continue
                
                # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                # ê²€ìƒ‰ì–´ì—ì„œ íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
                safe_name = "".join(c for c in name if c.isalnum() or c in (' ', '_', '-')).strip()
                safe_name = safe_name.replace(' ', '_')
                filename = f"{safe_name}_{count + 1}.jpg"
                filepath = os.path.join(save_dir, filename)
                
                urllib.request.urlretrieve(img_url, filepath)
                count += 1
                print(f"  ğŸ“¥ [{count}/{max_count}] {filename}")
                
            except Exception as e:
                # ì—ëŸ¬ ë¬´ì‹œí•˜ê³  ë‹¤ìŒ ì´ë¯¸ì§€ë¡œ
                continue
        
        print(f"âœ… ì™„ë£Œ: {name} â†’ {count}ì¥ ì €ì¥ë¨")
        
    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        
    finally:
        driver.quit()


# ============================================
# ìƒê²¬ë¡€ ì–¼êµ´ìƒ í…ŒìŠ¤íŠ¸ - í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘
# ============================================

if __name__ == "__main__":
    
    # í”„ë¦¬íŒ¨ìŠ¤ìƒ (í˜¸ê°í˜•) ì—°ì˜ˆì¸ ë¦¬ìŠ¤íŠ¸
    freepass_celebrities = [
        "ì°¨ì€ìš° ì–¼êµ´",
        "ì›ë¹ˆ ì–¼êµ´",
        "ì†¡ì¤‘ê¸° ì–¼êµ´",
        "ë°•ë³´ê²€ ì–¼êµ´",
        "ì†¡í˜œêµ ì–¼êµ´",
        "ìˆ˜ì§€ ì–¼êµ´",
        "ì•„ì´ìœ  ì–¼êµ´",
        "ê¹€íƒœí¬ ì–¼êµ´",
    ]
    
    # ë¬¸ì „ë°•ëŒ€ìƒ (ë°ˆìœ¼ë¡œ ìœ ëª…í•œ) ì—°ì˜ˆì¸ ë¦¬ìŠ¤íŠ¸
    # ì£¼ì˜: ì‹¤ì œ ë¹„í˜¸ê°ì´ ì•„ë‹ˆë¼ ë°ˆìœ¼ë¡œ ìœ ëª…í•´ì§„ ì¼€ì´ìŠ¤ë“¤
    moonjeonbakdae_celebrities = [
        "ì´ì±„ì˜ í”„ë¡œë¯¸ìŠ¤ë‚˜ì¸ ì–¼êµ´",
        # ì¶”ê°€ í•„ìš”ì‹œ ì—¬ê¸°ì— ì¶”ê°€
    ]
    
    print("=" * 50)
    print("ğŸ­ ìƒê²¬ë¡€ ì–¼êµ´ìƒ í…ŒìŠ¤íŠ¸ - ì´ë¯¸ì§€ í¬ë¡¤ëŸ¬")
    print("=" * 50)
    
    # í”„ë¦¬íŒ¨ìŠ¤ìƒ ì´ë¯¸ì§€ ìˆ˜ì§‘
    print("\nğŸ‘ [í”„ë¦¬íŒ¨ìŠ¤ìƒ] ì´ë¯¸ì§€ ìˆ˜ì§‘ ì‹œì‘...")
    for celeb in freepass_celebrities:
        crawling_img(celeb, "í”„ë¦¬íŒ¨ìŠ¤ìƒ", max_count=50)
    
    # ë¬¸ì „ë°•ëŒ€ìƒ ì´ë¯¸ì§€ ìˆ˜ì§‘
    print("\nğŸ‘ [ë¬¸ì „ë°•ëŒ€ìƒ] ì´ë¯¸ì§€ ìˆ˜ì§‘ ì‹œì‘...")
    for celeb in moonjeonbakdae_celebrities:
        crawling_img(celeb, "ë¬¸ì „ë°•ëŒ€ìƒ", max_count=50)
    
    print("\n" + "=" * 50)
    print("âœ… í¬ë¡¤ë§ ì™„ë£Œ!")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: ./dataset/í”„ë¦¬íŒ¨ìŠ¤ìƒ/, ./dataset/ë¬¸ì „ë°•ëŒ€ìƒ/")
    print("=" * 50)
